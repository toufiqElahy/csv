{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Exercise - Solutions\n",
    "\n",
    "### Follow along with the instructions in bold. Watch the solutions video if you get stuck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "** Source: https://datamarket.com/data/set/22ox/monthly-milk-production-pounds-per-cow-jan-62-dec-75#!ds=22ox&display=line **\n",
    "\n",
    "**Monthly milk production: pounds per cow. Jan 62 - Dec 75**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import numpy pandas and matplotlib **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use pandas to read the csv of the monthly-milk-production.csv file and set index_col='Month' **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "milk = pd.read_csv('monthly-milk-production.csv',index_col='Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check out the head of the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Milk Production</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-01-01 01:00:00</th>\n",
       "      <td>589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-02-01 01:00:00</th>\n",
       "      <td>561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-03-01 01:00:00</th>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-04-01 01:00:00</th>\n",
       "      <td>656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-05-01 01:00:00</th>\n",
       "      <td>727.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Milk Production\n",
       "Month                               \n",
       "1962-01-01 01:00:00            589.0\n",
       "1962-02-01 01:00:00            561.0\n",
       "1962-03-01 01:00:00            640.0\n",
       "1962-04-01 01:00:00            656.0\n",
       "1962-05-01 01:00:00            727.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Make the index a time series by using: **\n",
    "\n",
    "    milk.index = pd.to_datetime(milk.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "milk.index = pd.to_datetime(milk.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Plot out the time series data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17eb05d02e8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milk.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "** Let's attempt to predict a year's worth of data. (12 months or 12 steps into the future) **\n",
    "\n",
    "** Create a test train split using indexing (hint: use .head() or tail() or .iloc[]). We don't want a random train test split, we want to specify that the test set is the last 3 months of data is the test set, with everything before it is the training. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 168 entries, 1962-01-01 01:00:00 to 1975-12-01 01:00:00\n",
      "Data columns (total 1 columns):\n",
      "Milk Production    168 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 2.6 KB\n"
     ]
    }
   ],
   "source": [
    "milk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = milk.head(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = milk.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data\n",
    "\n",
    "** Use sklearn.preprocessing to scale the data using the MinMaxScaler. Remember to only fit_transform on the training data, then transform the test data. You shouldn't fit on the test data as well, otherwise you are assuming you would know about future behavior!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scaled = scaler.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_scaled = scaler.transform(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Function\n",
    "\n",
    "** We'll need a function that can feed batches of the training data. We'll need to do several things that are listed out as steps in the comments of the function. Remember to reference the previous batch method from the lecture for hints. Try to fill out the function template below, this is a pretty hard step, so feel free to reference the solutions! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(training_data,batch_size,steps):\n",
    "    \"\"\"\n",
    "    INPUT: Data, Batch Size, Time Steps per batch\n",
    "    OUTPUT: A tuple of y time series results. y[:,:-1] and y[:,1:]\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Use np.random.randint to set a random starting point index for the batch.\n",
    "    # Remember that each batch needs have the same number of steps in it.\n",
    "    # This means you should limit the starting point to len(data)-steps\n",
    "    \n",
    "    # STEP 2: Now that you have a starting index you'll need to index the data from\n",
    "    # the random start to random start + steps. Then reshape this data to be (1,steps)\n",
    "    \n",
    "    # STEP 3: Return the batches. You'll have two batches to return y[:,:-1] and y[:,1:]\n",
    "    # You'll need to reshape these into tensors for the RNN. Depending on your indexing it\n",
    "    # will be either .reshape(-1,steps-1,1) or .reshape(-1,steps,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(training_data,batch_size,steps):\n",
    "    \n",
    "    \n",
    "    # Grab a random starting point for each batch\n",
    "    rand_start = np.random.randint(0,len(training_data)-steps) \n",
    "\n",
    "    # Create Y data for time series in the batches\n",
    "    y_batch = np.array(training_data[rand_start:rand_start+steps+1]).reshape(1,steps+1)\n",
    "\n",
    "    return y_batch[:, :-1].reshape(-1, steps, 1), y_batch[:, 1:].reshape(-1, steps, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up The RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import TensorFlow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Constants\n",
    "\n",
    "** Define the constants in a single cell. You'll need the following (in parenthesis are the values I used in my solution, but you can play with some of these): **\n",
    "* Number of Inputs (1)\n",
    "* Number of Time Steps (12)\n",
    "* Number of Neurons per Layer (100)\n",
    "* Number of Outputs (1)\n",
    "* Learning Rate (0.003)\n",
    "* Number of Iterations for Training (4000)\n",
    "* Batch Size (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just one feature, the time series\n",
    "num_inputs = 1\n",
    "# Num of steps in each batch\n",
    "num_time_steps = 12\n",
    "# 100 neuron layer, play with this\n",
    "num_neurons = 100\n",
    "# Just one output, predicted time series\n",
    "num_outputs = 1\n",
    "\n",
    "## You can also try increasing iterations, but decreasing learning rate\n",
    "# learning rate you can play with this\n",
    "learning_rate = 0.03 \n",
    "# how many iterations to go through (training steps), you can play with this\n",
    "num_train_iterations = 4000\n",
    "# Size of the batch of data\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create Placeholders for X and y. (You can change the variable names if you want). The shape for these placeholders should be [None,num_time_steps-1,num_inputs] and [None, num_time_steps-1, num_outputs] The reason we use num_time_steps-1 is because each of these will be one step shorter than the original time steps size, because we are training the RNN network to predict one point into the future based on the input sequence.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, num_time_steps, num_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, num_time_steps, num_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create the RNN Layer, you have complete freedom over this, use tf.contrib.rnn and choose anything you want, OutputProjectionWrappers, BasicRNNCells, BasicLSTMCells, MultiRNNCell, GRUCell etc... Keep in mind not every combination will work well! (If in doubt, the solutions used an Outputprojection Wrapper around a basic LSTM cell with relu activation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also play around with GRUCell\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.contrib.rnn.BasicLSTMCell(num_units=num_neurons, activation=tf.nn.relu),\n",
    "    output_size=num_outputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now pass in the cells variable into tf.nn.dynamic_rnn, along with your first placeholder (X)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/output_projection_wrapper/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"C:\\Users\\anonymous\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\anonymous\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\anonymous\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-b518b633cb4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    759\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[0;32m   2773\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2774\u001b[0m     \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2775\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2776\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2602\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2603\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2604\u001b[1;33m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2605\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2606\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2552\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2553\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m-> 2554\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2556\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    744\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    745\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[1;31m# Pack state if using state tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[0;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;31m# Apply activity regularization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\rnn\\python\\ops\\core_rnn_cell.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, state)\u001b[0m\n\u001b[0;32m    224\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;34m\"\"\"Run the cell and output projection on inputs, starting from state.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[0mprojected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[0;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;31m# Apply activity regularization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, state)\u001b[0m\n\u001b[0;32m    399\u001b[0m       \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_or_size_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;31m# i = input_gate, j = new_input, f = forget_gate, o = output_gate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_linear\u001b[1;34m(args, output_size, bias, bias_initializer, kernel_initializer)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotal_arg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m         initializer=kernel_initializer)\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    358\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[0;32m    361\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m       return _true_getter(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mwrapped_custom_getter\u001b[1;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m     return custom_getter(\n\u001b[0;32m   1404\u001b[0m         \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1405\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   1406\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_custom_getter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[1;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     trainable = (variable in tf_variables.trainable_variables() or\n\u001b[0;32m    185\u001b[0m                  (isinstance(variable, tf_variables.PartitionedVariable) and\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[1;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     trainable = (variable in tf_variables.trainable_variables() or\n\u001b[0;32m    185\u001b[0m                  (isinstance(variable, tf_variables.PartitionedVariable) and\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m           use_resource=use_resource)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    662\u001b[0m                          \u001b[1;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 664\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable rnn/output_projection_wrapper/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"C:\\Users\\anonymous\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\anonymous\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\anonymous\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer\n",
    "\n",
    "** Create a Mean Squared Error Loss Function and use it to minimize an AdamOptimizer, remember to pass in your learning rate. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - y)) # MSE\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Initialize the global variables **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create an instance of tf.train.Saver() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session\n",
    "\n",
    "** Run a tf.Session that trains on the batches created by your next_batch function. Also add an a loss evaluation for every 100 training iterations. Remember to save your model after you are done training. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for iteration in range(num_train_iterations):\n",
    "        \n",
    "        X_batch, y_batch = next_batch(train_scaled,batch_size,num_time_steps)\n",
    "        sess.run(train, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            \n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "    \n",
    "    # Save Model for Later\n",
    "    saver.save(sess, \"./ex_time_series_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Future (Test Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Show the test_set (the last 12 months of your original complete data set) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now we want to attempt to predict these 12 months of data, using only the training data we had. To do this we will feed in a seed training_instance of the last 12 months of the training_set of data to predict 12 months into the future. Then we will be able to compare our generated 12 months to our actual true historical values from the test set! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Session\n",
    "\n",
    "### NOTE: Recall that our model is really only trained to predict 1 time step ahead, asking it to generate 12 steps is a big ask, and technically not what it was trained to do! Think of this more as generating new values based off some previous pattern, rather than trying to directly predict the future. You would need to go back to the original model and train the model to predict 12 time steps ahead to really get a higher accuracy on the test data. (Which has its limits due to the smaller size of our data set)\n",
    "\n",
    "** Fill out the session code below to generate 12 months of data based off the last 12 months of data from the training set. The hardest part about this is adjusting the arrays with their shapes and sizes. Reference the lecture for hints.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Use your Saver instance to restore your saved rnn time series model\n",
    "    saver.restore(sess, \"./ex_time_series_model\")\n",
    "\n",
    "    # Create a numpy array for your genreative seed from the last 12 months of the \n",
    "    # training set data. Hint: Just use tail(12) and then pass it to an np.array\n",
    "    train_seed = list(train_scaled[-12:])\n",
    "    \n",
    "    ## Now create a for loop that \n",
    "    for iteration in range(12):\n",
    "        X_batch = np.array(train_seed[-num_time_steps:]).reshape(1, num_time_steps, 1)\n",
    "        y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "        train_seed.append(y_pred[0, -1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Show the result of the predictions. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grab the portion of the results that are the generated values and apply inverse_transform on them to turn them back into milk production value units (lbs per cow). Also reshape the results to be (12,1) so we can easily add them to the test_set dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = scaler.inverse_transform(np.array(train_seed[12:]).reshape(12,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a new column on the test_set called \"Generated\" and set it equal to the generated results. You may get a warning about this, feel free to ignore it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Generated'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** View the test_set dataframe. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Plot out the two columns for comparison. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17eb05abd68>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVXFa6JVSqorTQq+UUlWcFnqllKri/g8IUxqhGzEa+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17eaee4a4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!\n",
    "\n",
    "Play around with the parameters and RNN layers, does a faster learning rate with more steps improve the model? What about GRU or BasicRNN units? What if you train the original model to not just predict one timestep ahead into the future, but 3 instead? Lots of stuff to add on here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
